{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sample_size, pathX, pathY):\n",
    "    f = gzip.open(pathX, 'r')\n",
    "\n",
    "    # read off unimportant bytes describing file protocol\n",
    "    image_size = 28 * 28\n",
    "    protocol_length = 16\n",
    "    f.read(protocol_length)\n",
    "\n",
    "    X = f.read(image_size * sample_size)\n",
    "    X = np.frombuffer(X, dtype=np.uint8).astype(np.float32)\n",
    "    X = X.reshape(sample_size, image_size)\n",
    "\n",
    "    f = gzip.open(pathY, 'r')\n",
    "\n",
    "    protocol_length = 8\n",
    "    f.read(protocol_length)\n",
    "    Y_temp = f.read(sample_size)\n",
    "    Y_temp = np.frombuffer(Y_temp, dtype=np.uint8)\n",
    "\n",
    "    Y = np.zeros([sample_size, 10], dtype='f')\n",
    "    for sample in range(sample_size):\n",
    "        Y[sample][Y_temp[sample]] = 1.0\n",
    "    \n",
    "    return [prep.scale(X), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        for layer in range(1, len(layers)):\n",
    "            self.w.append((2.0 * (np.random.randint(1e9, size=[layers[layer], layers[layer - 1]]) / 1e9)) - 1.0)\n",
    "            self.b.append(((2.0 * (np.random.randint(1e9, size=[layers[layer]]) / 1e9)) - 1.0).reshape([layers[layer], 1]))\n",
    "\n",
    "    def sigmoid(self, data):\n",
    "        epsilon = 1e-8\n",
    "        return 1.0 / (1.0 + np.exp(-data + epsilon))\n",
    "\n",
    "    def sigmoid_derivative(self, data):\n",
    "        temp = self.sigmoid(data)\n",
    "        return temp * (1 - temp)\n",
    "\n",
    "    def tanh(self, data):\n",
    "        return np.tanh(data)\n",
    "    \n",
    "    def tanh_derivative(self, data):\n",
    "        return 1 - np.tanh(data) ** 2\n",
    "\n",
    "    def activation(self, data):\n",
    "        return self.tanh(data)\n",
    "\n",
    "    def activation_derivative(self, data):\n",
    "        return self.tanh_derivative(data)\n",
    "\n",
    "    def backPropFast(self, train_X, train_Y, eta, lambd, p_keep):\n",
    "        m = len(train_X[0])\n",
    "\n",
    "        gradients_w = [np.zeros([self.layers[layer], self.layers[layer - 1]], dtype='f') for layer in range(1, len(self.layers))]\n",
    "        gradients_b = [np.zeros([self.layers[layer]], dtype='f') for layer in range(1, len(self.layers))]\n",
    "        activations = [train_X]\n",
    "        zs = [train_X]\n",
    "\n",
    "        last_layer = len(self.layers) - 2\n",
    "\n",
    "        for layer in range(len(self.layers) - 1):\n",
    "            zs.append(np.dot(self.w[layer], activations[-1]) + self.b[layer])\n",
    "            if layer == last_layer: activations.append(self.sigmoid(zs[-1]))\n",
    "            else: activations.append(self.activation(zs[-1]))\n",
    "            keeper = np.random.rand(activations[-1].shape[0], activations[-1].shape[1]) < p_keep[layer + 1]\n",
    "            activations[-1] = np.multiply(activations[-1], keeper)\n",
    "\n",
    "        delta_l = (activations[-1] - train_Y) * self.sigmoid_derivative(zs[-1])\n",
    "        gradients_b[-1] = delta_l.sum(axis=1)\n",
    "        gradients_w[-1] = np.dot(delta_l, np.transpose(activations[-2])) + lambd * self.w[-1] / float(m)\n",
    "\n",
    "        for layer in range(len(self.layers) - 2, 0, -1):\n",
    "            delta_l = np.dot(np.transpose(self.w[layer]), delta_l) * self.activation_derivative(zs[layer])\n",
    "            gradients_b[layer - 1] += delta_l.sum(axis=1)\n",
    "            gradients_w[layer - 1] += np.dot(delta_l, np.transpose(activations[layer - 1])) + lambd * self.w[layer - 1] / float(m)\n",
    "        \n",
    "        for layer in range(len(gradients_b)):\n",
    "            self.w[layer] -= eta * gradients_w[layer] / float(m)\n",
    "            self.b[layer] -= eta * gradients_b[layer].reshape([len(gradients_b[layer]), 1]) / float(m)\n",
    "\n",
    "    def train(self, train_X, train_Y, batch_size, eta=1.0, lambd=0.0, p_keep=None):\n",
    "        m = len(train_X[0]) #60000\n",
    "        if not p_keep: p_keep = [1.0 for i in range(len(self.layers))]\n",
    "        for batch in range(int(m / batch_size)):\n",
    "            X = train_X[ : , batch * batch_size : (batch + 1) * batch_size]\n",
    "            Y = train_Y[ : , batch * batch_size : (batch + 1) * batch_size]\n",
    "            self.backPropFast(X, Y, eta, lambd, p_keep)\n",
    "\n",
    "    def getOutputLayer(self, X, Y):\n",
    "        last_layer = len(self.layers) - 2\n",
    "        for layer in range(len(self.layers) - 1):\n",
    "            if layer == last_layer: X = self.sigmoid(np.dot(self.w[layer], X) + self.b[layer].reshape([self.layers[layer + 1], 1]))\n",
    "            else: X = self.activation(np.dot(self.w[layer], X) + self.b[layer].reshape([self.layers[layer + 1], 1]))\n",
    "        return X\n",
    "\n",
    "    def getAccuracy(self, X, Y):\n",
    "        predictions = np.argmax(self.getOutputLayer(X, Y), 0)\n",
    "        Y = np.argmax(Y, 0)\n",
    "        return (predictions == Y).sum() / float(len(Y))\n",
    "\n",
    "    def getLoss(self, X, Y):\n",
    "        loss = np.sum(np.square(self.getOutputLayer(X, Y) - Y)) / float(Y.shape[1])\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18537/2517381715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\"\"\"FMNIST DATASET\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FMNIST_Dataset/train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FMNIST_Dataset/train-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FMNIST_Dataset/t10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FMNIST_Dataset/t10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18537/91084037.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(sample_size, pathX, pathY)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mXr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0mmean_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# If mean_2 is not 'close to zero', it comes from the fact that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;31m# scale_ is very small so that mean_2 = mean_1/scale_ > 0, even\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_size = 60000\n",
    "test_size = 10000\n",
    "\n",
    "\"\"\"MNIST DATASET\"\"\"\n",
    "# train_X, train_Y = get_data(train_size, 'MNIST_Dataset/train-images-idx3-ubyte.gz', 'MNIST_Dataset/train-labels-idx1-ubyte.gz')\n",
    "# test_X, test_Y = [np.transpose(a) for a in get_data(test_size, 'MNIST_Dataset/t10k-images-idx3-ubyte.gz', 'MNIST_Dataset/t10k-labels-idx1-ubyte.gz')]\n",
    "\n",
    "\"\"\"FMNIST DATASET\"\"\"\n",
    "train_X, train_Y = get_data(train_size, 'FMNIST_Dataset/train-images-idx3-ubyte.gz', 'FMNIST_Dataset/train-labels-idx1-ubyte.gz')\n",
    "test_X, test_Y = [np.transpose(a) for a in get_data(test_size, 'FMNIST_Dataset/t10k-images-idx3-ubyte.gz', 'FMNIST_Dataset/t10k-labels-idx1-ubyte.gz')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [784, 256, 64, 10]\n",
    "batch_size = 100\n",
    "eta = 1.0\n",
    "epochs = 120\n",
    "lambd = 25.0\n",
    "decay_rate = 0.0005\n",
    "p_keep = [1.0, 0.3, 0.6, 1.0]\n",
    "\n",
    "network = Network(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 0.7868\n",
      "Epoch: 2 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18537/580451410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecay_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18537/686021697.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_X, train_Y, batch_size, eta, lambd, p_keep)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackPropFast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetOutputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18537/686021697.py\u001b[0m in \u001b[0;36mbackPropFast\u001b[0;34m(self, train_X, train_Y, eta, lambd, p_keep)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradients_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradients_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accuracies = np.zeros([epochs], dtype='f')\n",
    "test_accuracies = np.zeros([epochs], dtype='f')\n",
    "\n",
    "train_losses = np.zeros([epochs], dtype='f')\n",
    "test_losses = np.zeros([epochs], dtype='f')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:\", epoch + 1, end=\" \")\n",
    "\n",
    "    train_X, train_Y = shuffle(train_X, train_Y)\n",
    "    start_time = time.perf_counter()\n",
    "    network.train(np.transpose(train_X), np.transpose(train_Y), batch_size, eta, lambd, p_keep)\n",
    "    eta = eta / (1 + decay_rate * epoch)\n",
    "\n",
    "    train_losses[epoch] = network.getLoss(np.transpose(train_X), np.transpose(train_Y))\n",
    "    test_losses[epoch] = network.getLoss(test_X, test_Y)\n",
    "\n",
    "    train_accuracies[epoch] = network.getAccuracy(np.transpose(train_X), np.transpose(train_Y))\n",
    "    test_accuracies[epoch] = network.getAccuracy(test_X, test_Y)\n",
    "\n",
    "    print(test_accuracies[epoch])\n",
    "\n",
    "    # print(f\"Time taken in this epoch = {time.perf_counter() - start_time:0.1f} seconds\")\n",
    "\n",
    "plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(epochs), train_accuracies, label=\"Train accuracy\")\n",
    "plt.plot(np.arange(epochs), test_accuracies, label=\"Test accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Final train accuracy:\", train_accuracies[-1])\n",
    "print(\"Final test accuracy:\", test_accuracies[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
